import os
import json
import time
import requests
import feedparser
from datetime import datetime, timedelta, timezone

# =========================
# ENV
# =========================
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")

# daily reportÎäî Í∏∞Î≥∏Ï†ÅÏúºÎ°ú "Î¶¨Ìè¨Ìä∏ Ï†ÑÏö©" ÏÑ§Ï†ïÏùÑ Î≥¥ÎèÑÎ°ù!
# ÌïÑÏöîÌïòÎ©¥ GitHub Actions workflowÏóêÏÑú CONFIG_PATHÎ•º Î∞îÍøî ÎÅºÏö∏ Ïàò ÏûàÏùå
CONFIG_PATH = os.getenv("CONFIG_PATH", "config_report.json")

# ÏßÄÎÇú Î™á ÏãúÍ∞ÑÏπò Í∏∞ÏÇ¨Î°ú Î¶¨Ìè¨Ìä∏ ÎßåÎì§ÏßÄ (Í∏∞Î≥∏ 24ÏãúÍ∞Ñ)
LOOKBACK_HOURS = int(os.getenv("LOOKBACK_HOURS", "24"))

# =========================
# LOAD CONFIG
# =========================
def load_config(path: str) -> dict:
    # ÌòπÏãú ÌååÏùºÏù¥ ÏóÜÏúºÎ©¥ Í∏∞Ï°¥ config.jsonÎ°ú fallback (Ï¥àÍ∏∞ ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Ìé∏Ïùò)
    if not os.path.exists(path) and os.path.exists("config.json"):
        path = "config.json"

    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

config = load_config(CONFIG_PATH)

KEYWORDS = config.get("keywords", [])
RSS_FEEDS = config.get("rss_feeds", [])

# Í∞êÏ†ï ÌÉúÍπÖ (Í∞ÑÎã® Î≤ÑÏ†Ñ)
POSITIVE_WORDS = ["ÏàòÏ£º", "Ï¶ùÍ∞Ä", "ÌôïÎåÄ", "ÏÑ±Ïû•", "ÏÉÅÏäπ", "Í∞úÏÑ†", "Ìò∏Ï°∞", "ÌùëÏûê", "Ïù∏ÏÉÅ", "ÏÉÅÌñ•", "Í∞ïÏÑ∏", "ÌöåÎ≥µ"]
NEGATIVE_WORDS = ["Í∞êÏÜå", "ÌïòÎùΩ", "Ï†ÅÏûê", "Ï∂ïÏÜå", "Ïö∞Î†§", "Ïû¨Í≥† Ï¶ùÍ∞Ä", "ÎëîÌôî", "Î¶¨Ïä§ÌÅ¨", "Î∂ÄÏßÑ", "ÏïïÎ∞ï", "ÏïΩÏÑ∏", "Í≤ΩÍ≥†"]


# =========================
# HELPERS
# =========================
def safe_text(s):
    if not s:
        return ""
    return str(s)

def entry_datetime_utc(entry) -> datetime:
    """
    RSS entryÏóêÏÑú ÏãúÍ∞ÑÏùÑ ÏµúÎåÄÌïú ÏïàÏ†ÑÌïòÍ≤å UTC datetimeÏúºÎ°ú ÎΩëÏùå
    """
    # feedparserÎäî published_parsed / updated_parsed Îì±ÏùÑ time.struct_timeÎ°ú Ï§å
    t = None
    if hasattr(entry, "published_parsed") and entry.published_parsed:
        t = entry.published_parsed
    elif hasattr(entry, "updated_parsed") and entry.updated_parsed:
        t = entry.updated_parsed

    if t:
        return datetime.fromtimestamp(time.mktime(t), tz=timezone.utc)

    # ÏãúÍ∞ÑÏù¥ ÏóÜÏúºÎ©¥ "ÏßÄÍ∏à"ÏúºÎ°ú Ï≤òÎ¶¨
    return datetime.now(timezone.utc)

def match_keywords(text: str, keywords: list[str]) -> list[str]:
    text_l = text.lower()
    matched = []
    for k in keywords:
        k = safe_text(k).strip()
        if not k:
            continue
        if k.lower() in text_l:
            matched.append(k)
    return matched

def tag_sentiment(text: str) -> str:
    t = text.lower()
    pos = any(w.lower() in t for w in POSITIVE_WORDS)
    neg = any(w.lower() in t for w in NEGATIVE_WORDS)

    # Ïö∞ÏÑ†ÏàúÏúÑ: Îëò Îã§ ÏûàÏúºÎ©¥ Ï§ëÎ¶Ω
    if pos and not neg:
        return "üìà Í∏çÏ†ï"
    if neg and not pos:
        return "üìâ Î∂ÄÏ†ï"
    return "‚ö™ Ï§ëÎ¶Ω"

def slack_post(text: str):
    if not SLACK_WEBHOOK_URL:
        print("ERROR: SLACK_WEBHOOK_URL is not set")
        return False

    payload = {"text": text}
    r = requests.post(SLACK_WEBHOOK_URL, json=payload, timeout=20)
    if r.status_code >= 300:
        print("Slack error:", r.status_code, r.text[:300])
        return False
    return True


# =========================
# MAIN
# =========================
def main():
    now_utc = datetime.now(timezone.utc)
    cutoff = now_utc - timedelta(hours=LOOKBACK_HOURS)

    items = []
    seen_links = set()

    total_collected = 0
    total_matched = 0

    for feed_url in RSS_FEEDS:
        feed_url = safe_text(feed_url).strip()
        if not feed_url:
            continue

        d = feedparser.parse(feed_url)
        for e in d.entries:
            total_collected += 1

            title = safe_text(getattr(e, "title", ""))
            summary = safe_text(getattr(e, "summary", ""))
            link = safe_text(getattr(e, "link", ""))

            # Ï§ëÎ≥µ ÎßÅÌÅ¨ Ï†úÍ±∞
            if link and link in seen_links:
                continue
            if link:
                seen_links.add(link)

            pub_dt = entry_datetime_utc(e)
            if pub_dt < cutoff:
                continue

            text = f"{title}\n{summary}"
            matched = match_keywords(text, KEYWORDS)

            # ÌÇ§ÏõåÎìúÍ∞Ä ÌïòÎÇòÎèÑ ÏóÜÏúºÎ©¥ Î¶¨Ìè¨Ìä∏Ïóê Ïïà ÎÑ£Ïùå
            if not matched:
                continue

            total_matched += 1
            sentiment = tag_sentiment(text)

            items.append({
                "published": pub_dt,
                "title": title,
                "link": link,
                "matched": matched,
                "sentiment": sentiment,
            })

    # ÏµúÏã†Ïàú
    items.sort(key=lambda x: x["published"], reverse=True)

    # ÌÜµÍ≥Ñ
    total = len(items)
    pos = sum(1 for i in items if i["sentiment"].startswith("üìà"))
    neg = sum(1 for i in items if i["sentiment"].startswith("üìâ"))
    neu = total - pos - neg

    # ÏÉÅÏúÑ NÍ∞úÎßå
    TOP_N = int(os.getenv("TOP_N", "20"))
    top = items[:TOP_N]

    lines = []
    for i in top:
        mk = ", ".join(i["matched"][:5])
        lines.append(f"- {i['sentiment']} [{mk}] {i['title']}\n  {i['link']}")

    report_date_kst = (datetime.now(timezone.utc) + timedelta(hours=9)).strftime("%Y-%m-%d")
    header = (
        f"üìä *ÏùºÍ∞Ñ Î¶¨Ìè¨Ìä∏* ({report_date_kst}, ÏµúÍ∑º {LOOKBACK_HOURS}ÏãúÍ∞Ñ)\n"
        f"Ï¥ù {total}Í±¥ | üìà {pos} | üìâ {neg} | ‚ö™ {neu}\n"
    )
    body = "*Top Í∏∞ÏÇ¨*\n" + ("\n".join(lines) if lines else "- (Ìï¥Îãπ ÌÇ§ÏõåÎìú Í∏∞ÏÇ¨ ÏóÜÏùå)")

    ok = slack_post(header + "\n" + body)

    # Î°úÍ∑∏ (ActionsÏóêÏÑú ÌôïÏù∏)
    print(f"Collected: {total_collected}")
    print(f"Matched: {total_matched}")
    print(f"Sent: {1 if ok else 0}")


if __name__ == "__main__":
    main()
